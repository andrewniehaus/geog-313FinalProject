{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc16b86e-0644-4f38-82c8-05303c962a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy matplotlib tqdm shapely xarray rioxarray dask scikit-learn pystac-client planetary-computer requests rasterio\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box, mapping\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from rioxarray.merge import merge_datasets\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask import delayed\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "import pystac_client\n",
    "import planetary_computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1020e99-545f-4132-b68e-3b2e02e4624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Dask client\n",
    "client = Client(memory_limit='8GB')  # Adjust the memory limit based on your system's capacity\n",
    "\n",
    "# Print the dashboard link\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a18008-fc02-4740-ba38-f87be9c6b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_stac_items_bbox(url, collection, bbox, datetime, max_items=10, pc_flag=False, max_cloud_cover=2): \n",
    "    \"\"\"\n",
    "    This function retrieves the latest STAC items from a STAC API, filtered by cloud cover.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        The STAC API URL\n",
    "    collection : str\n",
    "        Collection ID to search in the STAC API\n",
    "    bbox : list or tuple\n",
    "        A tuple or list with coordinates of the target area for API search in the format (min x, min y, max x, max y)\n",
    "    datetime : str\n",
    "        ISO-8601 formatted date range, e.g., \"2020-01-01/2020-12-31\".\n",
    "    pc_flag : boolean\n",
    "        A boolean flag to specify whether the STAC API is Microsoft's planetary computer API. Default is set to False.\n",
    "    max_items : integer\n",
    "        Maximum number of items to retrieve from the STAC API. Default is 10.\n",
    "    max_cloud_cover : float\n",
    "        Maximum allowed cloud cover percentage for filtering. Default is 2%.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    items : Generator\n",
    "        The STAC item collection matching the query parameters.\n",
    "    \"\"\"\n",
    "    if pc_flag:\n",
    "        modifier = planetary_computer.sign_inplace\n",
    "    else:\n",
    "        modifier = None\n",
    "        \n",
    "    catalog = pystac_client.Client.open(\n",
    "        url=url,\n",
    "        modifier=modifier,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Query for items, including the cloud cover filter\n",
    "    search_results = catalog.search(\n",
    "        collections=[collection],\n",
    "        bbox=bbox,\n",
    "        datetime=datetime,  # ISO-8601 formatted date range\n",
    "        query={\"eo:cloud_cover\": {\"lt\": max_cloud_cover}},  # Cloud cover filter\n",
    "        sortby=[\"-properties.datetime\"],\n",
    "        max_items=max_items\n",
    "    )\n",
    "    items = search_results.item_collection()\n",
    "\n",
    "    return items\n",
    "\n",
    "# Define parameters for Charlottesville, Virginia (1-degree square around the city center)\n",
    "url = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "collection = \"landsat-c2-l2\"\n",
    "\n",
    "bbox = [-79.5, 37.9, -78.5, 38.9]  # 1-degree square bounding box around Charlottesville\n",
    "bbox_geometry = mapping(box(*bbox))\n",
    "time_range = \"2020-01-01/2020-12-31\"\n",
    "\n",
    "items = retrieve_stac_items_bbox(\n",
    "    url=url,\n",
    "    collection=collection,\n",
    "    bbox=bbox,\n",
    "    datetime=time_range,  # Pass the time range directly\n",
    "    max_items=1000,  # Retrieve up to 10 images\n",
    "    pc_flag=True  # Use Planetary Computer API\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba199261-aafe-4eef-a22d-fab70dfb78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_stac_asset_urls_all(items):\n",
    "    \"\"\"\n",
    "    Generate a dictionary of asset URLs for all available bands in the STAC items.\n",
    "    \n",
    "    Parameters:\n",
    "    items: list\n",
    "        A collection of STAC items.\n",
    "\n",
    "    Returns:\n",
    "    dict:\n",
    "        A dictionary where keys are band names and values are lists of URLs.\n",
    "    \"\"\"\n",
    "    asset_urls = {}\n",
    "    for item in items:\n",
    "        for asset_name, asset in item.assets.items():\n",
    "            if asset_name not in asset_urls:\n",
    "                asset_urls[asset_name] = []\n",
    "            asset_urls[asset_name].append(asset.href)\n",
    "    return asset_urls\n",
    "\n",
    "# Retrieve all band URLs\n",
    "asset_urls = gen_stac_asset_urls_all(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13edf49-1492-444a-b29d-20b2bf4a8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_rasters_with_dask_all(asset_urls):\n",
    "    \"\"\"\n",
    "    Open all band rasters using Dask.\n",
    "\n",
    "    Parameters:\n",
    "    asset_urls: dict\n",
    "        Dictionary where keys are band names and values are lists of URLs.\n",
    "\n",
    "    Returns:\n",
    "    dict:\n",
    "        Dictionary where keys are band names and values are lists of Dask datasets.\n",
    "    \"\"\"\n",
    "    return {band: [rxr.open_rasterio(url, lock=False, chunks={'x': 512, 'y': 512}).to_dataset(name=f\"{band}_{i}\")\n",
    "                   for i, url in enumerate(urls)]\n",
    "            for band, urls in asset_urls.items()}\n",
    "\n",
    "# Open datasets for all bands\n",
    "with ProgressBar():\n",
    "    band_datasets = open_rasters_with_dask_all(asset_urls)\n",
    "\n",
    "with ProgressBar():\n",
    "    red_datasets = open_rasters_with_dask(red_urls)\n",
    "    green_datasets = open_rasters_with_dask(green_urls)\n",
    "    blue_datasets = open_rasters_with_dask(blue_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481c044d-e1b7-4e3a-8b6c-f6163f86726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_in_batches(datasets, batch_size=5):\n",
    "    merged_result = None\n",
    "    for i in range(0, len(datasets), batch_size):\n",
    "        batch = datasets[i:i + batch_size]\n",
    "        batch_merged = xr.merge(batch, compat = 'override')  # Merge the current batch\n",
    "        if merged_result is None:\n",
    "            merged_result = batch_merged\n",
    "        else:\n",
    "            merged_result = xr.merge([merged_result, batch_merged], compat='override')  # Merge with previous result\n",
    "    return merged_result\n",
    "\n",
    "def dask_merge_datasets(datasets):\n",
    "    # Use delayed to merge datasets in batches\n",
    "    delayed_batches = merge_in_batches(datasets)\n",
    "    \n",
    "    # Convert merged dataset to Dask array\n",
    "    # We chunk the merged dataset after the delayed operations\n",
    "    dask_array = delayed_batches.chunk({'x': 2048, 'y': 2048})  # Ensure chunking is efficient\n",
    "    \n",
    "    # Compute the result in parallel once all tasks are delayed\n",
    "    result = dask.compute(dask_array)\n",
    "    return result[0]\n",
    "\n",
    "def dask_clip(dask_array, bbox_geometry, crs=4326):\n",
    "    \"\"\"\n",
    "    Clip a Dask array lazily to a given bounding box using RioClip.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dask_array : xarray.DataArray or dask.array\n",
    "        The Dask array to be clipped.\n",
    "    bbox_geometry : dict\n",
    "        The geometry for clipping (GeoJSON format).\n",
    "    crs : int, optional\n",
    "        The coordinate reference system (CRS) for the bounding box, default is 4326.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    clipped : xarray.DataArray\n",
    "        The clipped Dask array.\n",
    "    \"\"\"\n",
    "    return dask_array.rio.clip([bbox_geometry], crs=crs)\n",
    "\n",
    "def merge_all_bands(datasets):\n",
    "    return {band: dask_merge_datasets(dsets) for band, dsets in datasets.items()}\n",
    "\n",
    "def clip_all_bands(mosaics, bbox_geometry, crs=4326):\n",
    "    return {band: dask_clip(mosaic, bbox_geometry, crs=crs) for band, mosaic in mosaics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd56f1a-4c46-4d11-b53b-f955ba75525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    merged_bands = merge_all_bands(band_datasets)\n",
    "    clipped_bands = clip_all_bands(merged_bands, bbox_geometry)\n",
    "\n",
    "\n",
    "with ProgressBar():\n",
    "    mosaic_red[list(mosaic_red.data_vars)[0]].rio.to_raster(\"red_clipped.tif\")\n",
    "    mosaic_blue[list(mosaic_blue.data_vars)[0]].rio.to_raster(\"blue_clipped.tif\")\n",
    "    mosaic_green[list(mosaic_green.data_vars)[0]].rio.to_raster(\"green_clipped.tif\")\n",
    "\n",
    "# Combine all bands into a single xarray Dataset\n",
    "final_mosaic = xr.merge([clipped_bands[band] for band in clipped_bands], compat='override')\n",
    "\n",
    "# Save the final mosaic as a multi-band GeoTIFF\n",
    "final_mosaic = final_mosaic.squeeze()\n",
    "final_mosaic.rio.to_raster(\"final_mosaic_all_bands.tif\")\n",
    "\n",
    "print(\"Final mosaic bands:\", list(final_mosaic.data_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f0c7d-a950-4b4c-bcc5-964c9211d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available variables:\", list(final_mosaic.data_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1edea-4027-4e09-8ae8-caaf482c4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bridge between the codes:\n",
    "# Convert the final mosaic to a format suitable for clustering\n",
    "stacked_array = final_mosaic['uVBrdMABc%3D'].values\n",
    "\n",
    "# Reshape the array if needed for clustering\n",
    "valid_mask = stacked_array > 0\n",
    "valid_data = stacked_array[valid_mask]\n",
    "\n",
    "# Apply MiniBatch KMeans Clustering\n",
    "n_clusters = 10\n",
    "kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=1024)\n",
    "kmeans.fit(valid_data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422fec2b-adbc-4bdf-8efa-dfa26e825ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box\n",
    "import rioxarray as rxr\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "\n",
    "# Constants\n",
    "AOI = box(-105.0, 39.5, -104.5, 40.0)  # Bounding Box around Denver, CO\n",
    "TIME_RANGE = \"2023-01-01/2023-12-31\"\n",
    "BANDS = [\"red\", \"green\", \"blue\"]  # Target bands for clustering\n",
    "N_CLUSTERS = 10\n",
    "\n",
    "\n",
    "def search_and_load_data(catalog_url, collection, aoi, time_range, bands):\n",
    "    \"\"\"Searches for and loads satellite data for the given AOI, time range, and bands.\"\"\"\n",
    "    catalog = pystac_client.Client.open(catalog_url)\n",
    "    search = catalog.search(collections=[collection], bbox=aoi.bounds, datetime=time_range, limit=1)\n",
    "    item = next(search.get_items())\n",
    "    print(\"Selected Item:\", item.id)\n",
    "    \n",
    "    asset_hrefs = {key: pc.sign(asset.href) for key, asset in item.assets.items()}\n",
    "    return [rxr.open_rasterio(asset_hrefs[band]).squeeze() for band in bands]\n",
    "\n",
    "\n",
    "def stack_and_mask(arrays):\n",
    "    \"\"\"Stacks arrays along the last axis and masks invalid values.\"\"\"\n",
    "    stacked_array = np.stack([arr.values for arr in arrays], axis=-1)\n",
    "    valid_mask = np.all(stacked_array > 0, axis=-1)\n",
    "    return stacked_array, valid_mask\n",
    "\n",
    "\n",
    "def apply_clustering(data, mask, n_clusters):\n",
    "    \"\"\"Applies MiniBatch KMeans clustering to the valid data.\"\"\"\n",
    "    valid_data = data[mask]\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=1024)\n",
    "    kmeans.fit(valid_data)\n",
    "    \n",
    "    cluster_labels = -1 * np.ones(data.shape[:2], dtype=int)\n",
    "    cluster_labels[mask] = kmeans.predict(valid_data)\n",
    "    return cluster_labels, kmeans\n",
    "\n",
    "\n",
    "def compute_cluster_means(data, mask, labels, n_clusters):\n",
    "    \"\"\"Computes the average spectral signatures for each cluster.\"\"\"\n",
    "    valid_data = data[mask]\n",
    "    cluster_means = np.zeros((n_clusters, data.shape[-1]))\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_data = valid_data[labels[mask] == cluster]\n",
    "        cluster_means[cluster] = cluster_data.mean(axis=0)\n",
    "    return cluster_means\n",
    "\n",
    "\n",
    "def visualize_results(cluster_labels, cluster_means, bands):\n",
    "    \"\"\"Visualizes the clustering results and average spectral signatures.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # Clustered Image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Clustered Image\")\n",
    "    plt.imshow(cluster_labels, cmap=\"tab10\")\n",
    "    plt.colorbar(label=\"Cluster\")\n",
    "\n",
    "    # Spectral Signatures\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Average Spectral Signatures\")\n",
    "    for i, mean in enumerate(cluster_means):\n",
    "        plt.plot(mean, label=f\"Cluster {i}\")\n",
    "    plt.xticks(range(len(bands)), bands)\n",
    "    plt.xlabel(\"Band\")\n",
    "    plt.ylabel(\"Reflectance\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Workflow\n",
    "catalog_url = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "collection = \"landsat-c2-l2\"\n",
    "\n",
    "# Step 1: Search and load data\n",
    "arrays = search_and_load_data(catalog_url, collection, AOI, TIME_RANGE, BANDS)\n",
    "\n",
    "# Step 2: Stack and mask data\n",
    "stacked_array, valid_mask = stack_and_mask(arrays)\n",
    "\n",
    "# Step 3: Apply clustering\n",
    "cluster_labels, kmeans_model = apply_clustering(stacked_array, valid_mask, N_CLUSTERS)\n",
    "\n",
    "# Step 4: Compute cluster means\n",
    "cluster_means = compute_cluster_means(stacked_array, valid_mask, cluster_labels, N_CLUSTERS)\n",
    "\n",
    "# Step 5: Visualize results\n",
    "visualize_results(cluster_labels, cluster_means, BANDS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
